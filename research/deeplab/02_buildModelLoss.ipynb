{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.3\n"
     ]
    }
   ],
   "source": [
    "from deeplab import common, model\n",
    "from deeplab.utils import train_utils\n",
    "from deeplab.core import utils\n",
    "\n",
    "from tensorflow.keras.utils import OrderedEnqueuer\n",
    "from tensorflow.contrib import slim as contrib_slim\n",
    "from slim.nets import resnet_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from lib import dataloader, modelbuilder, lr_schedular\n",
    "\n",
    "from albumentations import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# %config IPCompleter.greedy=True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "flags.DEFINE_boolean('fine_tune_batchnorm', True, 'fine tune batchnorm')\n",
    "flags.DEFINE_float('weight_decay', 1e-4, 'weight decay')\n",
    "\n",
    "flags.DEFINE_enum('optimizer', 'momentum', ['momentum', 'adam'],\n",
    "                  'Which optimizer to use.')\n",
    "\n",
    "# Momentum optimizer flags\n",
    "\n",
    "flags.DEFINE_enum('learning_policy', 'poly', ['poly', 'step'],\n",
    "                  'Learning rate policy for training.')\n",
    "\n",
    "# Use 0.007 when training on PASCAL augmented training set, train_aug. When\n",
    "# fine-tuning on PASCAL trainval set, use learning rate=0.0001.\n",
    "flags.DEFINE_float('base_learning_rate', .0001,\n",
    "                   'The base learning rate for model training.')\n",
    "\n",
    "flags.DEFINE_float('decay_steps', 0.0,\n",
    "                   'Decay steps for polynomial learning rate schedule.')\n",
    "\n",
    "flags.DEFINE_float('end_learning_rate', 0.0,\n",
    "                   'End learning rate for polynomial learning rate schedule.')\n",
    "\n",
    "flags.DEFINE_float('learning_rate_decay_factor', 0.1,\n",
    "                   'The rate to decay the base learning rate.')\n",
    "\n",
    "flags.DEFINE_integer('learning_rate_decay_step', 2000,\n",
    "                     'Decay the base learning rate at a fixed step.')\n",
    "\n",
    "flags.DEFINE_float('learning_power', 0.9,\n",
    "                   'The power value used in the poly learning policy.')\n",
    "\n",
    "flags.DEFINE_integer('training_number_of_steps', 3000,\n",
    "                     'The number of steps used for training')\n",
    "\n",
    "flags.DEFINE_float('momentum', 0.9, 'The momentum value to use')\n",
    "\n",
    "# Adam optimizer flags\n",
    "flags.DEFINE_float('adam_learning_rate', 0.001,\n",
    "                   'Learning rate for the adam optimizer.')\n",
    "flags.DEFINE_float('adam_epsilon', 1e-08, 'Adam optimizer epsilon.')\n",
    "\n",
    "# slow start\n",
    "flags.DEFINE_integer('slow_start_step', 0,\n",
    "                     'Training model with small learning rate for few steps.')\n",
    "\n",
    "flags.DEFINE_float('slow_start_learning_rate', 1e-4,\n",
    "                   'Learning rate employed during slow start.')\n",
    "\n",
    "# one cycle policy parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_to_num_classes {'semantic': 3}\n",
      "crop_size [256, 256]\n",
      "atrous_rates [2, 4, 8]\n",
      "output_stride 16\n",
      "preprocessed_images_dtype <dtype: 'float32'>\n",
      "merge_method max\n",
      "add_image_level_feature True\n",
      "image_pooling_crop_size None\n",
      "image_pooling_stride [1, 1]\n",
      "aspp_with_batch_norm True\n",
      "aspp_with_separable_conv False\n",
      "multi_grid [1, 2]\n",
      "decoder_output_stride [2]\n",
      "decoder_use_separable_conv False\n",
      "logits_kernel_size 1\n",
      "model_variant resnet_mod\n",
      "depth_multiplier 1.0\n",
      "divisible_by None\n",
      "prediction_with_upsampled_logits True\n",
      "dense_prediction_cell_config None\n",
      "nas_architecture_options {'nas_stem_output_num_conv_filters': 20, 'nas_use_classification_head': False, 'nas_remove_os32_stride': False}\n",
      "use_bounded_activation False\n",
      "aspp_with_concat_projection True\n",
      "aspp_with_squeeze_and_excitation False\n",
      "aspp_convs_filters 256\n",
      "decoder_use_sum_merge False\n",
      "decoder_filters 256\n",
      "decoder_output_is_logits True\n",
      "image_se_uses_qsigmoid False\n",
      "label_weights 1.0\n",
      "sync_batch_norm_method None\n",
      "batch_norm_decay 0.9997\n"
     ]
    }
   ],
   "source": [
    "crop_size = [256, 256]\n",
    "outputs_to_num_classes = {'semantic': 3}\n",
    "\n",
    "model_options = common.ModelOptions(\n",
    "    outputs_to_num_classes,\n",
    "    crop_size,\n",
    "    output_stride=16\n",
    ")._replace(\n",
    "    add_image_level_feature=True,\n",
    "    aspp_with_batch_norm=True,\n",
    "    aspp_with_separable_conv=False,\n",
    "    decoder_use_separable_conv=False,\n",
    "    decoder_output_is_logits=True,\n",
    "    logits_kernel_size=1,\n",
    "    decoder_output_stride=[2],\n",
    "    multi_grid=[1,2],\n",
    "    atrous_rates=[2,4,8],\n",
    "    model_variant='resnet_mod') \n",
    "\n",
    "for key, value in model_options._asdict().items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  min_resize_value: None\n",
      "  max_resize_value: None\n",
      "  resize_factor: None\n",
      "  keep_aspect_ratio: True\n",
      "  logits_kernel_size: 1\n",
      "  model_variant: mobilenet_v2\n",
      "  image_pyramid: None\n",
      "  add_image_level_feature: True\n",
      "  image_pooling_crop_size: None\n",
      "  image_pooling_stride: ['1', '1']\n",
      "  aspp_with_batch_norm: True\n",
      "  aspp_with_separable_conv: True\n",
      "  multi_grid: [1, 2, 4]\n",
      "  depth_multiplier: 1.0\n",
      "  divisible_by: None\n",
      "  decoder_output_stride: None\n",
      "  decoder_use_separable_conv: True\n",
      "  merge_method: max\n",
      "  prediction_with_upsampled_logits: True\n",
      "  dense_prediction_cell_json: \n",
      "  nas_stem_output_num_conv_filters: 20\n",
      "  nas_use_classification_head: False\n",
      "  nas_remove_os32_stride: False\n",
      "  use_bounded_activation: False\n",
      "  aspp_with_concat_projection: True\n",
      "  aspp_with_squeeze_and_excitation: False\n",
      "  aspp_convs_filters: 256\n",
      "  decoder_use_sum_merge: False\n",
      "  decoder_filters: 256\n",
      "  decoder_output_is_logits: False\n",
      "  image_se_uses_qsigmoid: False\n",
      "  label_weights: None\n",
      "  batch_norm_decay: 0.9997\n",
      "  f: /home/lis-paul/.local/share/jupyter/runtime/kernel-d58f206d-151c-4947-a940-d3e921afb6da.json\n",
      "  fine_tune_batchnorm: True\n",
      "  weight_decay: 0.0001\n",
      "  optimizer: momentum\n",
      "  learning_policy: poly\n",
      "  base_learning_rate: 0.0001\n",
      "  decay_steps: 0.0\n",
      "  end_learning_rate: 0.0\n",
      "  learning_rate_decay_factor: 0.1\n",
      "  learning_rate_decay_step: 2000\n",
      "  learning_power: 0.9\n",
      "  training_number_of_steps: 3000\n",
      "  momentum: 0.9\n",
      "  adam_learning_rate: 0.001\n",
      "  adam_epsilon: 1e-08\n",
      "  slow_start_step: 0\n",
      "  slow_start_learning_rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "for key in FLAGS.__flags.keys():\n",
    "    print('  {}: {}'.format(key, getattr(FLAGS, key)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 292\n",
      "- training:       248\n",
      "- validation:      44\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/lis-paul/data/dsb2018/dsb2018_sub1/'\n",
    "X_trn, Y_trn, X_val, Y_val = dataloader.load_img_dir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranf=list(np.random.ranf(8)+10*np.random.ranf(1))\n",
    "AUG = Compose([\n",
    "#         CoarseDropout(max_holes=64, max_height=8, max_width=8, min_holes=None, min_height=None, min_width=None, \n",
    "#                   fill_value=ranf, always_apply=False, p=.9),\n",
    "        GaussNoise(var_limit=(0.0, 0.05), mean=0, p=.5),\n",
    "        GaussianBlur(blur_limit=3, p=.5),\n",
    "        Flip(p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0, scale_limit=(0.2, 1), rotate_limit=15, \n",
    "                         interpolation=0, border_mode=cv2.BORDER_REFLECT_101, value=0, mask_value=0, p=1),\n",
    "        ElasticTransform(alpha=100, sigma=10, alpha_affine=1, p=0.7, \n",
    "                         interpolation=0, border_mode=cv2.BORDER_REFLECT_101, value=0, mask_value=0),\n",
    "        RandomCrop(256, 256, always_apply=True, p=1.0)\n",
    "    ], p=0.9)\n",
    "\n",
    "AUG_val = RandomCrop(256, 256, always_apply=True, p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.Dataloader(X_trn, Y_trn, batch_size=8, patch_size=(256,256), augmenter=AUG, shuffle=True)\n",
    "# val_dl   = dataloader.Dataloader(X_val, Y_val, batch_size=16, patch_size=(256,256), augmenter=AUG_val, shuffle=False)\n",
    "\n",
    "xx,yy = train_dl[0]\n",
    "# print(xx.dtype, yy[0].dtype, yy[1].dtype, yy[2].dtype)\n",
    "# print(xx.shape, yy[0].shape, yy[1].shape, yy[2].shape)\n",
    "# print(np.max(xx), np.max(yy[0]), yy[1].dtype, yy[2].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.9993363229371175, 0.9993919671255781)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(yy[2]), np.max(yy[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = SegmentationMultiGenerator(datasets, folder) # My keras.utils.sequence object\n",
    "\n",
    "def generator():\n",
    "    multi_enqueuer = OrderedEnqueuer(train_dl, use_multiprocessing=True)\n",
    "    multi_enqueuer.start(workers=8, max_queue_size=16)\n",
    "    while True:\n",
    "        xx, yy = next(multi_enqueuer.get())\n",
    "        yield xx[...,np.newaxis], yy[0,...,np.newaxis], np.stack((yy[1], yy[2]),axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build network and get losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(generator,\n",
    "                                 output_types=(tf.uint8, tf.float32, tf.float32),\n",
    "                                 output_shapes=(tf.TensorShape([None, 256, 256, 1]),\n",
    "                                                tf.TensorShape([None, 256, 256, 1]),\n",
    "                                                tf.TensorShape([None, 256, 256, 2]))\n",
    "                                )\n",
    "\n",
    "itr = dataset.make_one_shot_iterator()\n",
    "sample = itr.get_next()\n",
    "\n",
    "logits, prob_loss, grad_loss = modelbuilder.my_model(sample,\n",
    "                                    model_options,\n",
    "                                    weight_decay=FLAGS.weight_decay,\n",
    "                                    is_training=True,\n",
    "                                    fine_tune_batch_norm=FLAGS.fine_tune_batchnorm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAGS.training_number_of_steps = 500\n",
    "# gs = tf.train.get_or_create_global_step()\n",
    "# momentum = FLAGS.momentum\n",
    "\n",
    "# learning_rate = lr_schedular.learning_rate_range_test(gs, FLAGS.training_number_of_steps, 1e-5, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup learning rate and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = tf.train.get_or_create_global_step()\n",
    "ss = (FLAGS.training_number_of_steps * 0.9)/2\n",
    "\n",
    "# update_op = tf.assign_add(gs, 1)\n",
    "# with tf.control_dependencies([update_op]):\n",
    "learning_rate = lr_schedular.cyclic_learning_rate(gs,\n",
    "                                                  learning_rate=2e-5,\n",
    "                                                  max_lr=1e-3,\n",
    "                                                  step_size=ss,\n",
    "                                                  max_steps=FLAGS.training_number_of_steps,\n",
    "                                                  scale_rate=0.9,\n",
    "                                                  mode='triangular',\n",
    "                                                  policy='one_cycle',\n",
    "                                                  name='oclr')\n",
    "\n",
    "momentum = lr_schedular.cyclical_momentum(  gs,\n",
    "                                            min_momentum=0.95,\n",
    "                                            max_momentum=0.98,\n",
    "                                            step_size=ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = train_utils.get_model_learning_rate(\n",
    "#   FLAGS.learning_policy,\n",
    "#   FLAGS.base_learning_rate,\n",
    "#   FLAGS.learning_rate_decay_step,\n",
    "#   FLAGS.learning_rate_decay_factor,\n",
    "#   FLAGS.training_number_of_steps,\n",
    "#   FLAGS.learning_power,\n",
    "#   FLAGS.slow_start_step,\n",
    "#   FLAGS.slow_start_learning_rate,\n",
    "#   decay_steps=FLAGS.decay_steps,\n",
    "#   end_learning_rate=FLAGS.end_learning_rate)\n",
    "# gs = tf.train.get_or_create_global_step()\n",
    "# momentum = FLAGS.momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = tf.get_default_graph()\n",
    "# with g.as_default():\n",
    "#     with tf.Session(graph=g) as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         for n in range(0,FLAGS.training_number_of_steps):\n",
    "#             gs, lr = sess.run([global_step, learning_rate])\n",
    "            \n",
    "#             print(lr, gs)\n",
    "#             writer = tf.summary.FileWriter(\"output3/lr2\", sess.graph)\n",
    "#             tf.summary.scalar('lr', lr)\n",
    "#             update_op = tf.assign_add(global_step, 1)\n",
    "        \n",
    "#         writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hard pixels mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_example_mining_step = tf.cast(tf.math.ceil(FLAGS.training_number_of_steps * 0.8), tf.int64)\n",
    "top_k_percent_pixels = 0.5\n",
    "grad_loss_sum = tf.losses.compute_weighted_loss(grad_loss)\n",
    "grad_loss_flatten = tf.reshape(grad_loss, shape=[-1])\n",
    "\n",
    "s1 = tf.to_float(tf.shape(grad_loss_flatten)[0])\n",
    "ratio = tf.minimum(1.0, tf.cast(gs / hard_example_mining_step, tf.float32))\n",
    "top_k_pixels = tf.to_int32((ratio * top_k_percent_pixels + (1.0 - ratio)) * s1 )\n",
    "top_k_losses, _ = tf.nn.top_k(grad_loss_flatten,\n",
    "                              k=top_k_pixels,\n",
    "                              sorted=True,\n",
    "                              name='top_k_percent_pixels')\n",
    "grad_loss_topk = tf.reduce_sum(top_k_losses) / tf.cast(top_k_pixels, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s2 = tf.shape(grad_loss)\n",
    "# s3 = tf.shape(grad_loss_flatten)\n",
    "# s4 = tf.shape(top_k_losses)\n",
    "\n",
    "    \n",
    "# g = tf.get_default_graph()\n",
    "# with g.as_default():\n",
    "#     with tf.Session(graph=g) as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         for e in range(1,100):\n",
    "# #             sess.run([train_op, check_op])\n",
    "#             gs2, lr = sess.run([gs, learning_rate])\n",
    "#             print(lr, gs2)\n",
    "#             writer = tf.summary.FileWriter(\"output3/lr2\", sess.graph)\n",
    "#             tf.summary.scalar('top_k_pixels', top_k_pixels)\n",
    "# #             tf.assign_add(gs, 1)\n",
    "#             print(s1.eval(), s2.eval(), s3.eval(), grad_loss_sum.eval(), ratio.eval(), top_k_pixels.eval(), s4.eval(), grad_loss_topk.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'prob/weighted_loss/value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'grad/mse_grad/Mul:0' shape=(?, 256, 256, 2) dtype=float32>,\n",
       " <tf.Tensor 'weighted_loss/value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Add_1:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio = tf.minimum(1.0, tf.cast(gs / hard_example_mining_step, tf.float32))\n",
    "# top_k_pixels = tf.to_int32(ratio * top_k_percent_pixels + (1.0 - ratio))  ## don't multiply s1\n",
    "# top_k_losses, _ = tf.nn.top_k(grad_loss_flatten,\n",
    "#                               k=top_k_pixels,\n",
    "#                               sorted=True,\n",
    "#                               name='top_k_percent_pixels')\n",
    "# grad_loss_topk = tf.reduce_sum(top_k_losses)\n",
    "\n",
    "\n",
    "\n",
    "total_loss = tf.add(prob_loss , grad_loss_topk * 20)\n",
    "tf.losses.add_loss(total_loss)\n",
    "tf.losses.get_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.momentum.MomentumOptimizer at 0x7f877dd2dc50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if FLAGS.optimizer == 'momentum':\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "elif FLAGS.optimizer == 'adam':\n",
    "    optimizer = tf.train.AdamOptimizer(\n",
    "    learning_rate=FLAGS.adam_learning_rate, epsilon=FLAGS.adam_epsilon)\n",
    "else:\n",
    "    raise ValueError('Unknown optimizer')\n",
    "\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve update ops for batch normalization\n",
    "# update_ops = tf.GraphKeys.UPDATE_OPS\n",
    "# # Define optimizer for training\n",
    "# with tf.control_dependencies(tf.get_collection(update_ops)):\n",
    "#     optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<tf.Tensor 'grad_loss_pix:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'prob_loss_pix:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'prob_pred:0' shape=() dtype=string>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.add(tf.summary.scalar('prob_loss', prob_loss))\n",
    "summaries.add(tf.summary.scalar('grad_loss', grad_loss_sum))\n",
    "summaries.add(tf.summary.scalar('total_loss', total_loss))\n",
    "summaries.add(tf.summary.scalar('learning_rate', learning_rate))\n",
    "summaries.add(tf.summary.scalar('momentum', momentum))\n",
    "summaries.add(tf.summary.scalar('topk_percent', top_k_pixels))\n",
    "summaries.add(tf.summary.scalar('grad_loss_topk', grad_loss_topk))\n",
    "\n",
    "tensor_name = logits.op.name\n",
    "# summaries.add(tf.summary.histogram(tensor_name + '/activation', logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'prob_pred:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'prob_loss_pix:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'grad_loss:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'prob_loss:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'grad_loss_pix:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'total_loss:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'learning_rate:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'momentum:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'topk_percent:0' shape=() dtype=string>,\n",
       " <tf.Tensor 'grad_loss_topk:0' shape=() dtype=string>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_op = tf.summary.merge(list(summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = contrib_slim.learning.create_train_op(\n",
    "            total_loss,\n",
    "            optimizer,\n",
    "            gs,\n",
    "            summarize_gradients=False,\n",
    "            clip_gradient_norm=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define tf session config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_config = tf.ConfigProto(\n",
    "        allow_soft_placement=True, \n",
    "        log_device_placement=False)\n",
    "        \n",
    "# session_config.gpu_options.allow_growth = True,\n",
    "# session_config.gpu_options.per_process_gpu_memory_fraction = 0.8 \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "nowstr = now.strftime(\"%Y%m%d-%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_op = tf.add_check_numerics_ops()\n",
    "\n",
    "# g = tf.get_default_graph()\n",
    "# with g.as_default():\n",
    "#     with tf.Session(graph=g) as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         for e in range(1,500):\n",
    "#             sess.run([train_op, check_op])\n",
    "#             print(gs.eval(), learning_rate.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lis-paul/miniconda3/envs/ocr/lib/python3.7/site-packages/tensorflow/contrib/slim/python/slim/learning.py:737: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.MonitoredTrainingSession\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path slim_output/20200619-23:22:29_oclr+m95-98_wd1e-4_g*20_topk50/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:global_step/sec: 4.02949\n",
      "INFO:tensorflow:Recording summary at step 20.\n",
      "INFO:tensorflow:global_step/sec: 4.18459\n",
      "INFO:tensorflow:Recording summary at step 40.\n",
      "INFO:tensorflow:global step 49: loss = 3.2111 (0.213 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 4.01291\n",
      "INFO:tensorflow:Recording summary at step 60.\n",
      "INFO:tensorflow:Recording summary at step 84.\n",
      "INFO:tensorflow:global_step/sec: 4.54473\n",
      "INFO:tensorflow:global step 99: loss = 1.6898 (0.213 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 103.\n",
      "INFO:tensorflow:global_step/sec: 3.77255\n",
      "INFO:tensorflow:global_step/sec: 4.27891\n",
      "INFO:tensorflow:Recording summary at step 124.\n",
      "INFO:tensorflow:global_step/sec: 4.60993\n",
      "INFO:tensorflow:Recording summary at step 146.\n",
      "INFO:tensorflow:global step 149: loss = 1.0048 (0.218 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 167.\n",
      "INFO:tensorflow:global_step/sec: 3.91106\n",
      "INFO:tensorflow:Recording summary at step 187.\n",
      "INFO:tensorflow:global step 199: loss = 1.7899 (0.215 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 207.\n",
      "INFO:tensorflow:Recording summary at step 230.\n",
      "INFO:tensorflow:global step 249: loss = 0.9777 (0.217 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 250.\n",
      "INFO:tensorflow:Recording summary at step 269.\n",
      "INFO:tensorflow:Recording summary at step 292.\n",
      "INFO:tensorflow:global step 299: loss = 1.2759 (0.222 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 312.\n",
      "INFO:tensorflow:Recording summary at step 332.\n",
      "INFO:tensorflow:global step 349: loss = 0.7385 (0.216 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 354.\n",
      "INFO:tensorflow:Recording summary at step 374.\n",
      "INFO:tensorflow:Recording summary at step 394.\n",
      "INFO:tensorflow:global step 399: loss = 0.6150 (0.217 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 414.\n",
      "INFO:tensorflow:Recording summary at step 436.\n",
      "INFO:tensorflow:global step 449: loss = 0.8108 (0.220 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 455.\n",
      "INFO:tensorflow:Recording summary at step 473.\n",
      "INFO:tensorflow:Recording summary at step 496.\n",
      "INFO:tensorflow:global step 499: loss = 1.2507 (0.217 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 516.\n",
      "INFO:tensorflow:Recording summary at step 536.\n",
      "INFO:tensorflow:global step 549: loss = 0.9542 (0.218 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 558.\n",
      "INFO:tensorflow:Recording summary at step 578.\n",
      "INFO:tensorflow:Recording summary at step 595.\n",
      "INFO:tensorflow:global step 599: loss = 0.6849 (0.217 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 618.\n",
      "INFO:tensorflow:Recording summary at step 637.\n",
      "INFO:tensorflow:global step 649: loss = 1.0538 (0.434 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 657.\n",
      "INFO:tensorflow:Recording summary at step 679.\n",
      "INFO:tensorflow:Recording summary at step 698.\n",
      "INFO:tensorflow:global step 699: loss = 0.8667 (0.225 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 717.\n",
      "INFO:tensorflow:Recording summary at step 737.\n",
      "INFO:tensorflow:global step 749: loss = 0.8294 (0.232 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 756.\n",
      "INFO:tensorflow:Recording summary at step 773.\n",
      "INFO:tensorflow:Recording summary at step 793.\n",
      "INFO:tensorflow:global step 799: loss = 0.7057 (0.238 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 810.\n",
      "INFO:tensorflow:Recording summary at step 828.\n",
      "INFO:tensorflow:global step 849: loss = 0.9622 (0.242 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 849.\n",
      "INFO:tensorflow:Recording summary at step 866.\n",
      "INFO:tensorflow:Recording summary at step 885.\n",
      "INFO:tensorflow:global step 899: loss = 0.9263 (0.231 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 906.\n",
      "INFO:tensorflow:Recording summary at step 924.\n",
      "INFO:tensorflow:Recording summary at step 944.\n",
      "INFO:tensorflow:global step 949: loss = 0.6146 (0.232 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 964.\n",
      "INFO:tensorflow:Recording summary at step 982.\n",
      "INFO:tensorflow:global step 999: loss = 0.7051 (0.236 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1002.\n",
      "INFO:tensorflow:Recording summary at step 1020.\n",
      "INFO:tensorflow:Recording summary at step 1038.\n",
      "INFO:tensorflow:global step 1049: loss = 0.5590 (0.246 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1059.\n",
      "INFO:tensorflow:Recording summary at step 1078.\n",
      "INFO:tensorflow:Recording summary at step 1095.\n",
      "INFO:tensorflow:global step 1099: loss = 0.6428 (0.235 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1116.\n",
      "INFO:tensorflow:Recording summary at step 1133.\n",
      "INFO:tensorflow:global step 1149: loss = 0.7732 (0.341 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1151.\n",
      "INFO:tensorflow:Recording summary at step 1172.\n",
      "INFO:tensorflow:Recording summary at step 1190.\n",
      "INFO:tensorflow:global step 1199: loss = 1.2845 (0.253 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1209.\n",
      "INFO:tensorflow:Recording summary at step 1228.\n",
      "INFO:tensorflow:Recording summary at step 1246.\n",
      "INFO:tensorflow:global step 1249: loss = 0.7505 (0.242 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1266.\n",
      "INFO:tensorflow:Recording summary at step 1284.\n",
      "INFO:tensorflow:global step 1299: loss = 0.5852 (0.235 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1301.\n",
      "INFO:tensorflow:Recording summary at step 1322.\n",
      "INFO:tensorflow:Recording summary at step 1338.\n",
      "INFO:tensorflow:global step 1349: loss = 0.6340 (0.245 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1356.\n",
      "INFO:tensorflow:Recording summary at step 1376.\n",
      "INFO:tensorflow:Recording summary at step 1394.\n",
      "INFO:tensorflow:global step 1399: loss = 0.7555 (0.252 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1413.\n",
      "INFO:tensorflow:Recording summary at step 1432.\n",
      "INFO:tensorflow:global step 1449: loss = 0.7258 (0.229 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1450.\n",
      "INFO:tensorflow:Recording summary at step 1470.\n",
      "INFO:tensorflow:Recording summary at step 1488.\n",
      "INFO:tensorflow:global step 1499: loss = 0.5830 (0.242 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1505.\n",
      "INFO:tensorflow:Recording summary at step 1525.\n",
      "INFO:tensorflow:Recording summary at step 1543.\n",
      "INFO:tensorflow:global step 1549: loss = 1.3539 (0.253 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1561.\n",
      "INFO:tensorflow:Recording summary at step 1581.\n",
      "INFO:tensorflow:Recording summary at step 1597.\n",
      "INFO:tensorflow:global step 1599: loss = 0.5560 (0.248 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1616.\n",
      "INFO:tensorflow:Recording summary at step 1632.\n",
      "INFO:tensorflow:global step 1649: loss = 0.7010 (0.370 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1650.\n",
      "INFO:tensorflow:Recording summary at step 1670.\n",
      "INFO:tensorflow:Recording summary at step 1689.\n",
      "INFO:tensorflow:global step 1699: loss = 0.8077 (0.247 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1708.\n",
      "INFO:tensorflow:Recording summary at step 1726.\n",
      "INFO:tensorflow:Recording summary at step 1744.\n",
      "INFO:tensorflow:global step 1749: loss = 0.6851 (0.251 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1764.\n",
      "INFO:tensorflow:Recording summary at step 1782.\n",
      "INFO:tensorflow:global step 1799: loss = 0.4340 (0.231 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1800.\n",
      "INFO:tensorflow:Recording summary at step 1820.\n",
      "INFO:tensorflow:Recording summary at step 1838.\n",
      "INFO:tensorflow:global step 1849: loss = 0.6846 (0.249 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1856.\n",
      "INFO:tensorflow:Recording summary at step 1876.\n",
      "INFO:tensorflow:Recording summary at step 1891.\n",
      "INFO:tensorflow:global step 1899: loss = 0.9525 (0.247 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1911.\n",
      "INFO:tensorflow:Recording summary at step 1929.\n",
      "INFO:tensorflow:Recording summary at step 1946.\n",
      "INFO:tensorflow:global step 1949: loss = 0.8356 (0.237 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 1967.\n",
      "INFO:tensorflow:Recording summary at step 1984.\n",
      "INFO:tensorflow:global step 1999: loss = 0.6696 (0.248 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2003.\n",
      "INFO:tensorflow:Recording summary at step 2023.\n",
      "INFO:tensorflow:Recording summary at step 2040.\n",
      "INFO:tensorflow:global step 2049: loss = 0.3620 (0.252 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2060.\n",
      "INFO:tensorflow:Recording summary at step 2076.\n",
      "INFO:tensorflow:Recording summary at step 2094.\n",
      "INFO:tensorflow:global step 2099: loss = 0.9221 (0.249 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2114.\n",
      "INFO:tensorflow:Recording summary at step 2132.\n",
      "INFO:tensorflow:global step 2149: loss = 0.4155 (0.336 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2150.\n",
      "INFO:tensorflow:Recording summary at step 2170.\n",
      "INFO:tensorflow:Recording summary at step 2188.\n",
      "INFO:tensorflow:global step 2199: loss = 0.7516 (0.240 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2208.\n",
      "INFO:tensorflow:Recording summary at step 2226.\n",
      "INFO:tensorflow:Recording summary at step 2244.\n",
      "INFO:tensorflow:global step 2249: loss = 1.3312 (0.244 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2265.\n",
      "INFO:tensorflow:Saving checkpoint to path slim_output/20200619-23:22:29_oclr+m95-98_wd1e-4_g*20_topk50/model.ckpt\n",
      "INFO:tensorflow:Recording summary at step 2283.\n",
      "INFO:tensorflow:global step 2299: loss = 1.2539 (0.235 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2301.\n",
      "INFO:tensorflow:Recording summary at step 2321.\n",
      "INFO:tensorflow:Recording summary at step 2339.\n",
      "INFO:tensorflow:global step 2349: loss = 0.4757 (0.247 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2356.\n",
      "INFO:tensorflow:Recording summary at step 2375.\n",
      "INFO:tensorflow:Recording summary at step 2392.\n",
      "INFO:tensorflow:global step 2399: loss = 0.7241 (0.243 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2412.\n",
      "INFO:tensorflow:Recording summary at step 2430.\n",
      "INFO:tensorflow:Recording summary at step 2448.\n",
      "INFO:tensorflow:global step 2449: loss = 0.5217 (0.239 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2468.\n",
      "INFO:tensorflow:Recording summary at step 2483.\n",
      "INFO:tensorflow:global step 2499: loss = 0.3809 (0.266 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2502.\n",
      "INFO:tensorflow:Recording summary at step 2519.\n",
      "INFO:tensorflow:Recording summary at step 2536.\n",
      "INFO:tensorflow:global step 2549: loss = 0.6938 (0.243 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2556.\n",
      "INFO:tensorflow:Recording summary at step 2573.\n",
      "INFO:tensorflow:Recording summary at step 2591.\n",
      "INFO:tensorflow:global step 2599: loss = 0.6038 (0.245 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2610.\n",
      "INFO:tensorflow:Recording summary at step 2627.\n",
      "INFO:tensorflow:Recording summary at step 2645.\n",
      "INFO:tensorflow:global step 2649: loss = 0.6885 (0.959 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2661.\n",
      "INFO:tensorflow:Recording summary at step 2680.\n",
      "INFO:tensorflow:Recording summary at step 2699.\n",
      "INFO:tensorflow:global step 2699: loss = 1.6193 (0.326 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2715.\n",
      "INFO:tensorflow:Recording summary at step 2735.\n",
      "INFO:tensorflow:global step 2749: loss = 0.8221 (0.242 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2753.\n",
      "INFO:tensorflow:Recording summary at step 2769.\n",
      "INFO:tensorflow:Recording summary at step 2788.\n",
      "INFO:tensorflow:global step 2799: loss = 0.4981 (0.251 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2806.\n",
      "INFO:tensorflow:Recording summary at step 2826.\n",
      "INFO:tensorflow:Recording summary at step 2844.\n",
      "INFO:tensorflow:global step 2849: loss = 0.6034 (0.249 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2862.\n",
      "INFO:tensorflow:Recording summary at step 2881.\n",
      "INFO:tensorflow:Recording summary at step 2898.\n",
      "INFO:tensorflow:global step 2899: loss = 0.9111 (0.281 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2914.\n",
      "INFO:tensorflow:Recording summary at step 2932.\n",
      "INFO:tensorflow:Recording summary at step 2947.\n",
      "INFO:tensorflow:global step 2949: loss = 1.4273 (0.251 sec/step)\n",
      "INFO:tensorflow:Recording summary at step 2967.\n",
      "INFO:tensorflow:Recording summary at step 2985.\n",
      "INFO:tensorflow:global step 2999: loss = 0.7803 (0.249 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    contrib_slim.learning.train(\n",
    "          train_op,\n",
    "          logdir=f\"slim_output/{nowstr}_oclr+m95-98_wd1e-4_g*20_topk50\",\n",
    "          log_every_n_steps=50,\n",
    "          number_of_steps=FLAGS.training_number_of_steps,\n",
    "          global_step=gs,\n",
    "          session_config=session_config,\n",
    "          summary_op=summary_op,\n",
    "          save_summaries_secs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = tf.get_default_graph()\n",
    "# with g.as_default():\n",
    "#     with tf.Session(graph=g) as sess:\n",
    "# #         img = tf.random_uniform(\n",
    "# #                 (4, crop_size[0], crop_size[1], 1))\n",
    "# #         img = tf.convert_to_tensor(xx[...,np.newaxis], dtype=tf.uint8)\n",
    "# #         print(img.shape)\n",
    "# #         print(img.dtype)\n",
    "# #         outputs_to_scales_to_logits = model.multi_scale_logits(\n",
    "# #                                         inputs,\n",
    "# #                                         model_options,\n",
    "# #                                         image_pyramid=[1.0])\n",
    "\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "# #         outputs_to_scales_to_logits = sess.run(outputs_to_logits, feed_dict={'input_layer:0': img.eval(), 'training:0':True})\n",
    "# #         outputs = sess.run(outputs_scaled, feed_dict={'input_layer:0': img.eval(), 'training:0':True})\n",
    "# #         output0 = sess.run(logits)\n",
    "#         ploss = sess.run(prob_loss)\n",
    "#         gloss = sess.run(grad_loss)\n",
    "#         tloss = sess.run(total_loss)\n",
    "#         print(ploss.shape, gloss.shape, tloss.shape)\n",
    "# #         print((output0['semantic']['merged_logits']).shape)\n",
    "#         writer = tf.summary.FileWriter(\"output3/total\", sess.graph)\n",
    "    \n",
    "# #         tf.summary.scalar('yaw_total_loss', yaw_total_loss)\n",
    "# #         tf.summary.scalar('pitch_total_loss', pitch_total_loss)\n",
    "# #         tf.summary.scalar('roll_total_loss', roll_total_loss)\n",
    "    \n",
    "#         writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
