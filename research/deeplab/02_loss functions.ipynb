{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.3\n"
     ]
    }
   ],
   "source": [
    "from deeplab import common, model\n",
    "from deeplab.utils import train_utils\n",
    "from deeplab.core import utils\n",
    "\n",
    "from tensorflow.keras.utils import OrderedEnqueuer\n",
    "from tensorflow.contrib import slim as contrib_slim\n",
    "from slim.nets import resnet_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from lib import dataloader\n",
    "\n",
    "from albumentations import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# %config IPCompleter.greedy=True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('f', '', 'kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = [256, 256]\n",
    "outputs_to_num_classes = {'semantic': 3}\n",
    "\n",
    "model_options = common.ModelOptions(\n",
    "    outputs_to_num_classes,\n",
    "    crop_size,\n",
    "    output_stride=8\n",
    ")._replace(\n",
    "    add_image_level_feature=True,\n",
    "    aspp_with_batch_norm=True,\n",
    "    aspp_with_separable_conv=False,\n",
    "    decoder_use_separable_conv=False,\n",
    "    decoder_output_is_logits=True,\n",
    "    logits_kernel_size=1,\n",
    "    decoder_output_stride=[4,2],\n",
    "    multi_grid=[1,2],\n",
    "    atrous_rates=[2,4,6],\n",
    "    model_variant='resnet_mod') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_to_num_classes {'semantic': 3}\n",
      "crop_size [256, 256]\n",
      "atrous_rates [2, 4, 6]\n",
      "output_stride 8\n",
      "preprocessed_images_dtype <dtype: 'float32'>\n",
      "merge_method max\n",
      "add_image_level_feature True\n",
      "image_pooling_crop_size None\n",
      "image_pooling_stride [1, 1]\n",
      "aspp_with_batch_norm True\n",
      "aspp_with_separable_conv False\n",
      "multi_grid [1, 2]\n",
      "decoder_output_stride [4, 2]\n",
      "decoder_use_separable_conv False\n",
      "logits_kernel_size 1\n",
      "model_variant resnet_mod\n",
      "depth_multiplier 1.0\n",
      "divisible_by None\n",
      "prediction_with_upsampled_logits True\n",
      "dense_prediction_cell_config None\n",
      "nas_architecture_options {'nas_stem_output_num_conv_filters': 20, 'nas_use_classification_head': False, 'nas_remove_os32_stride': False}\n",
      "use_bounded_activation False\n",
      "aspp_with_concat_projection True\n",
      "aspp_with_squeeze_and_excitation False\n",
      "aspp_convs_filters 256\n",
      "decoder_use_sum_merge False\n",
      "decoder_filters 256\n",
      "decoder_output_is_logits True\n",
      "image_se_uses_qsigmoid False\n",
      "label_weights 1.0\n",
      "sync_batch_norm_method None\n",
      "batch_norm_decay 0.9997\n"
     ]
    }
   ],
   "source": [
    "for key, value in model_options._asdict().items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 292\n",
      "- training:       248\n",
      "- validation:      44\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/lis-paul/data/dsb2018/dsb2018_sub1/'\n",
    "X_trn, Y_trn, X_val, Y_val = dataloader.load_img_dir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranf=list(np.random.ranf(8)+10*np.random.ranf(1))\n",
    "AUG = Compose([\n",
    "#         CoarseDropout(max_holes=64, max_height=8, max_width=8, min_holes=None, min_height=None, min_width=None, \n",
    "#                   fill_value=ranf, always_apply=False, p=.9),\n",
    "        GaussNoise(var_limit=(0.0, 0.05), mean=0, p=.5),\n",
    "        GaussianBlur(blur_limit=3, p=.5),\n",
    "        Flip(p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0, scale_limit=(0.2, 1), rotate_limit=15, \n",
    "                         interpolation=0, border_mode=cv2.BORDER_REFLECT_101, value=0, mask_value=0, p=1),\n",
    "        ElasticTransform(alpha=100, sigma=10, alpha_affine=1, p=0.7, \n",
    "                         interpolation=0, border_mode=cv2.BORDER_REFLECT_101, value=0, mask_value=0),\n",
    "        RandomCrop(256, 256, always_apply=True, p=1.0)\n",
    "    ], p=0.9)\n",
    "\n",
    "AUG_val = RandomCrop(256, 256, always_apply=True, p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader.Dataloader(X_trn, Y_trn, batch_size=16, patch_size=(256,256), augmenter=AUG, shuffle=True)\n",
    "val_dl   = dataloader.Dataloader(X_val, Y_val, batch_size=4, patch_size=(256,256), augmenter=AUG_val, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx, yy = train_dl[0]\n",
    "\n",
    "# for arr in [xx, yy[0], yy[1], yy[2]]:\n",
    "#     dataloader.show_some_data(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 float64 float64 float64\n",
      "(16, 256, 256) (16, 256, 256) (16, 256, 256) (16, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "xx,yy = train_dl[0]\n",
    "print(xx.dtype, yy[0].dtype, yy[1].dtype, yy[2].dtype)\n",
    "print(xx.shape, yy[0].shape, yy[1].shape, yy[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 256, 256, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((yy[1], yy[2]), axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = SegmentationMultiGenerator(datasets, folder) # My keras.utils.sequence object\n",
    "\n",
    "def generator():\n",
    "    multi_enqueuer = OrderedEnqueuer(train_dl, use_multiprocessing=True)\n",
    "    multi_enqueuer.start(workers=8, max_queue_size=8)\n",
    "    while True:\n",
    "        xx, yy = next(multi_enqueuer.get())\n",
    "        yield xx[...,np.newaxis], yy[0,...,np.newaxis], np.stack((yy[1], yy[2]),axis=-1)\n",
    "        \n",
    "        \n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator,\n",
    "                                         output_types=(tf.uint8, tf.float32, tf.float32),\n",
    "                                         output_shapes=(tf.TensorShape([None, 256, 256, 1]),\n",
    "                                                        tf.TensorShape([None, 256, 256, 1]),\n",
    "                                                        tf.TensorShape([None, 256, 256, 2]))\n",
    "                                        )\n",
    "\n",
    "itr = dataset.make_one_shot_iterator()\n",
    "sample = itr.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'semantic': <tf.Tensor 'semantic:0' shape=(?, 128, 128, 256) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "# imgs = np.random.uniform.ipynb_checkpoints/size=(4, crop_size[0], crop_size[1], 1))\n",
    "# imgs = tf.random_uniform((4, crop_size[0], crop_size[1], 1))\n",
    "# print(xx.shape)\n",
    "# logits = model.multi_scale_logits(sample[0],\n",
    "#                        model_options,\n",
    "#                        image_pyramid=[1.0],\n",
    "#                        weight_decay=0.0001,\n",
    "#                        is_training=True,\n",
    "#                        fine_tune_batch_norm=False,\n",
    "#                        nas_training_hyper_parameters=None)\n",
    "# print(logits['semantic']['merged_logits'].shape)\n",
    "\n",
    "logits = model._get_logits(\n",
    "        sample[0],\n",
    "        model_options=model_options,\n",
    "        weight_decay=0.0001,\n",
    "        reuse=tf.AUTO_REUSE,\n",
    "        is_training=True,\n",
    "        fine_tune_batch_norm=True)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = tf.get_default_graph()\n",
    "# with g.as_default():\n",
    "#     with tf.Session(graph=g) as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         output0 = sess.run(logits)\n",
    "#         writer = tf.summary.FileWriter(\"output3/logit_resnet_v1_50_beta\", sess.graph)\n",
    "#         writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'semantic': <tf.Tensor 'semantic:0' shape=(?, 128, 128, 256) dtype=float32>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_scope = resnet_utils.resnet_arg_scope(\n",
    "        weight_decay=0.0001,\n",
    "        batch_norm_decay=0.95,\n",
    "        batch_norm_epsilon=1e-5,\n",
    "        batch_norm_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## upsample the output logits\n",
    "# logits = utils.resize_bilinear(logits['semantic']['merged_logits'],\n",
    "#                                crop_size,\n",
    "#                                logits['semantic']['merged_logits'].dtype)\n",
    "logits = tf.image.resize_bilinear(\n",
    "          logits['semantic'],\n",
    "          crop_size,\n",
    "          align_corners=True)\n",
    "print(logits.shape)\n",
    "\n",
    "with tf.variable_scope(\"prob\"):\n",
    "#     with contrib_slim.arg_scope(arg_scope):\n",
    "    prob = contrib_slim.conv2d(logits, 1, [1, 1], stride=1,\n",
    "                             scope='logit_prob')\n",
    "    prob_loss = tf.losses.sigmoid_cross_entropy(\n",
    "                sample[1], \n",
    "                prob, \n",
    "                weights=1.0, \n",
    "                label_smoothing=0, \n",
    "                scope=\"bce_prob\",\n",
    "                loss_collection=tf.GraphKeys.LOSSES, \n",
    "                reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    "            )\n",
    "\n",
    "with tf.variable_scope(\"grad\"):\n",
    "    grad = contrib_slim.conv2d(logits, 2, [1, 1], stride=1,\n",
    "                             scope='logit_grad')\n",
    "    grad_loss = tf.losses.mean_squared_error(\n",
    "                sample[2],\n",
    "                grad,\n",
    "                weights=1.0,\n",
    "                scope=\"mse_grad\",\n",
    "                loss_collection=tf.GraphKeys.LOSSES,\n",
    "                reduction=tf.losses.Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    "            ) \n",
    "print(prob.shape, grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = tf.add(prob_loss , grad_loss*5)\n",
    "tf.losses.add_loss(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'prob/bce_prob/value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'grad/mse_grad/value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Add:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.get_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "() () ()\n"
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "with g.as_default():\n",
    "    with tf.Session(graph=g) as sess:\n",
    "#         img = tf.random_uniform(\n",
    "#                 (4, crop_size[0], crop_size[1], 1))\n",
    "#         img = tf.convert_to_tensor(xx[...,np.newaxis], dtype=tf.uint8)\n",
    "#         print(img.shape)\n",
    "#         print(img.dtype)\n",
    "#         outputs_to_scales_to_logits = model.multi_scale_logits(\n",
    "#                                         inputs,\n",
    "#                                         model_options,\n",
    "#                                         image_pyramid=[1.0])\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "#         outputs_to_scales_to_logits = sess.run(outputs_to_logits, feed_dict={'input_layer:0': img.eval(), 'training:0':True})\n",
    "#         outputs = sess.run(outputs_scaled, feed_dict={'input_layer:0': img.eval(), 'training:0':True})\n",
    "#         output0 = sess.run(logits)\n",
    "        ploss = sess.run(prob_loss)\n",
    "        gloss = sess.run(grad_loss)\n",
    "        tloss = sess.run(total_loss)\n",
    "        print(ploss.shape, gloss.shape, tloss.shape)\n",
    "#         print((output0['semantic']['merged_logits']).shape)\n",
    "        writer = tf.summary.FileWriter(\"output3/total\", sess.graph)\n",
    "    \n",
    "#         tf.summary.scalar('yaw_total_loss', yaw_total_loss)\n",
    "#         tf.summary.scalar('pitch_total_loss', pitch_total_loss)\n",
    "#         tf.summary.scalar('roll_total_loss', roll_total_loss)\n",
    "    \n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs_to_scales_to_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7a707d102e76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add name to graph node so we can add to summary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput_type_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs_to_scales_to_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOUTPUT_TYPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m output_type_dict[model.MERGED_LOGITS_SCOPE] = tf.identity(\n\u001b[1;32m      4\u001b[0m                         output_type_dict[model.MERGED_LOGITS_SCOPE], name=common.OUTPUT_TYPE)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputs_to_scales_to_logits' is not defined"
     ]
    }
   ],
   "source": [
    "# Add name to graph node so we can add to summary.\n",
    "output_type_dict = outputs_to_scales_to_logits[common.OUTPUT_TYPE]\n",
    "output_type_dict[model.MERGED_LOGITS_SCOPE] = tf.identity(\n",
    "                        output_type_dict[model.MERGED_LOGITS_SCOPE], name=common.OUTPUT_TYPE)num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "for output, num_classes in six.iteritems(outputs_to_num_classes):\n",
    "    print(output, num_classes)\n",
    "    print(outputs_to_scales_to_logits[output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(samples[common.LABEL].shape)\n",
    "\n",
    "print(model_options.label_weights)\n",
    "\n",
    "print(FLAGS.upsample_logits)\n",
    "\n",
    "(?, 513, 513, 1)\n",
    "\n",
    "1.0\n",
    "\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 256, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##network output \n",
    "# for output, num_classes in six.iteritems(outputs_to_num_classes):\n",
    "#     train_utils.add_softmax_cross_entropy_loss_for_each_scale(\n",
    "#         outputs_to_scales_to_logits[output],\n",
    "#         tf.convert_to_tensor(yy[0,...,np.newaxis], dtype=tf.uint8),\n",
    "#         3,\n",
    "#         255,\n",
    "#         loss_weight=model_options.label_weights,\n",
    "#         upsample_logits=True,\n",
    "#         hard_example_mining_step=0,\n",
    "#         top_k_percent_pixels=1.0,\n",
    "#         scope=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'semantic'\n",
    "logits = outputs_to_scales_to_logits[output]['merged_logits']\n",
    "labels = tf.convert_to_tensor(yy[0,...,np.newaxis], dtype=tf.uint8)\n",
    "num_classes = 3\n",
    "ignore_label = 255\n",
    "gt_is_matting_map = False\n",
    "loss_weight=model_options.label_weights\n",
    "upsample_logits=True\n",
    "hard_example_mining_step=0\n",
    "top_k_percent_pixels=1.0\n",
    "scope=output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_1:0\", shape=(524288,), dtype=float32)\n",
      "logits before:Tensor(\"ResizeBilinear_2:0\", shape=(8, 256, 256, 3), dtype=float32)\n",
      "logits after:Tensor(\"Reshape_1:0\", shape=(524288, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from deeplab.core import preprocess_utils, utils\n",
    "scale='scale1'\n",
    "loss_scope = None\n",
    "if scope:\n",
    "    loss_scope = '%s_%s' % (scope, scale)\n",
    "\n",
    "if upsample_logits:\n",
    "    # Label is not downsampled, and instead we upsample logits.\n",
    "    logits = tf.image.resize_bilinear(\n",
    "                logits,\n",
    "                preprocess_utils.resolve_shape(labels, 4)[1:3],\n",
    "                align_corners=True)\n",
    "    scaled_labels = labels\n",
    "else:\n",
    "  # Label is downsampled to the same size as logits.\n",
    "  # When gt_is_matting_map = true, label downsampling with nearest neighbor\n",
    "  # method may introduce artifacts. However, to avoid ignore_label from\n",
    "  # being interpolated with other labels, we still perform nearest neighbor\n",
    "  # interpolation.\n",
    "  # TODO(huizhongc): Change to bilinear interpolation by processing padded\n",
    "  # and non-padded label separately\n",
    "\n",
    "    scaled_labels = tf.image.resize_nearest_neighbor(\n",
    "                        labels,\n",
    "                        preprocess_utils.resolve_shape(logits, 4)[1:3],\n",
    "                        align_corners=True)\n",
    "\n",
    "scaled_labels = tf.reshape(scaled_labels, shape=[-1])\n",
    "weights = utils.get_label_weight_mask(\n",
    "    scaled_labels, ignore_label, num_classes, label_weights=loss_weight)\n",
    "# Dimension of keep_mask is equal to the total number of pixels.\n",
    "keep_mask = tf.cast(\n",
    "    tf.not_equal(scaled_labels, ignore_label), dtype=tf.float32)\n",
    "print(keep_mask)\n",
    "train_labels = None\n",
    "print(f'logits before:{logits}')\n",
    "logits = tf.reshape(logits, shape=[-1, num_classes])\n",
    "print(f'logits after:{logits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.one_hot(\n",
    "      scaled_labels, num_classes, on_value=1.0, off_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _div_maybe_zero(total_loss, num_present):\n",
    "  \"\"\"Normalizes the total loss with the number of present pixels.\"\"\"\n",
    "  return tf.to_float(num_present > 0) * tf.math.divide(\n",
    "      total_loss,\n",
    "      tf.maximum(1e-5, num_present))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"semantic_scale1/pixel_losses/Reshape_2:0\", shape=(524288,), dtype=float32)\n",
      "Tensor(\"semantic_scale1/Sum:0\", shape=(), dtype=float32)\n",
      "Tensor(\"semantic_scale1/Sum_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"semantic_scale1/mul_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "default_loss_scope = ('softmax_all_pixel_loss'\n",
    "                      if top_k_percent_pixels == 1.0 else\n",
    "                      'softmax_hard_example_mining')\n",
    "with tf.name_scope(loss_scope, default_loss_scope,\n",
    "                   [logits, train_labels, weights]):\n",
    "  # Compute the loss for all pixels.\n",
    "  pixel_losses = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "      labels=tf.stop_gradient(\n",
    "          train_labels, name='train_labels_stop_gradient'),\n",
    "      logits=logits,\n",
    "      name='pixel_losses')\n",
    "  weighted_pixel_losses = tf.multiply(pixel_losses, weights)\n",
    "  print(pixel_losses)\n",
    "  if top_k_percent_pixels == 1.0:\n",
    "    total_loss = tf.reduce_sum(weighted_pixel_losses)\n",
    "    print(total_loss)\n",
    "    num_present = tf.reduce_sum(keep_mask)\n",
    "    print(num_present)\n",
    "    loss = _div_maybe_zero(total_loss, num_present)\n",
    "    print(loss)\n",
    "    tf.losses.add_loss(loss)\n",
    "  else:\n",
    "    num_pixels = tf.to_float(tf.shape(logits)[0])\n",
    "    # Compute the top_k_percent pixels based on current training step.\n",
    "    if hard_example_mining_step == 0:\n",
    "      # Directly focus on the top_k pixels.\n",
    "      top_k_pixels = tf.to_int32(top_k_percent_pixels * num_pixels)\n",
    "    else:\n",
    "      # Gradually reduce the mining percent to top_k_percent_pixels.\n",
    "      global_step = tf.to_float(tf.train.get_or_create_global_step())\n",
    "      ratio = tf.minimum(1.0, global_step / hard_example_mining_step)\n",
    "      top_k_pixels = tf.to_int32(\n",
    "          (ratio * top_k_percent_pixels + (1.0 - ratio)) * num_pixels)\n",
    "    top_k_losses, _ = tf.nn.top_k(weighted_pixel_losses,\n",
    "                                  k=top_k_pixels,\n",
    "                                  sorted=True,\n",
    "                                  name='top_k_percent_pixels')\n",
    "    \n",
    "    total_loss = tf.reduce_sum(top_k_losses)\n",
    "    num_present = tf.reduce_sum(\n",
    "        tf.to_float(tf.not_equal(top_k_losses, 0.0)))\n",
    "    loss = _div_maybe_zero(total_loss, num_present)\n",
    "    tf.losses.add_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACTIVATIONS',\n",
       " 'ASSET_FILEPATHS',\n",
       " 'BIASES',\n",
       " 'CONCATENATED_VARIABLES',\n",
       " 'COND_CONTEXT',\n",
       " 'EVAL_STEP',\n",
       " 'GLOBAL_STEP',\n",
       " 'GLOBAL_VARIABLES',\n",
       " 'INIT_OP',\n",
       " 'LOCAL_INIT_OP',\n",
       " 'LOCAL_RESOURCES',\n",
       " 'LOCAL_VARIABLES',\n",
       " 'LOSSES',\n",
       " 'METRIC_VARIABLES',\n",
       " 'MODEL_VARIABLES',\n",
       " 'MOVING_AVERAGE_VARIABLES',\n",
       " 'QUEUE_RUNNERS',\n",
       " 'READY_FOR_LOCAL_INIT_OP',\n",
       " 'READY_OP',\n",
       " 'REGULARIZATION_LOSSES',\n",
       " 'RESOURCES',\n",
       " 'SAVEABLE_OBJECTS',\n",
       " 'SAVERS',\n",
       " 'SUMMARIES',\n",
       " 'SUMMARY_OP',\n",
       " 'TABLE_INITIALIZERS',\n",
       " 'TRAINABLE_RESOURCE_VARIABLES',\n",
       " 'TRAINABLE_VARIABLES',\n",
       " 'TRAIN_OP',\n",
       " 'UPDATE_OPS',\n",
       " 'VARIABLES',\n",
       " 'WEIGHTS',\n",
       " 'WHILE_CONTEXT',\n",
       " '_STREAMING_MODEL_PORTS',\n",
       " '_SUMMARY_COLLECTION',\n",
       " '_VARIABLE_COLLECTIONS',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.GraphKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'semantic_scale1/mul_1:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.LOSSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 256, 256, 1)\n",
      "<dtype: 'uint8'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: The name 'input_layer:0' refers to a Tensor which does not exist. The operation, 'input_layer', does not exist in the graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/ocr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1092\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ocr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ocr/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3531\u001b[0m                          \u001b[0;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3532\u001b[0;31m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[1;32m   3533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'input_layer:0' refers to a Tensor which does not exist. The operation, 'input_layer', does not exist in the graph.\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5d9b80e38395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         logits = sess.run(logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         outputs_to_scales_to_logits = sess.run(outputs_to_logits, feed_dict={'input_layer:0': img.eval(), 'training:0':True})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input_layer:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#         loss = sess.run(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         output0 = sess.run(outputs_to_scales_to_logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ocr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ocr/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1095\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: The name 'input_layer:0' refers to a Tensor which does not exist. The operation, 'input_layer', does not exist in the graph."
     ]
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "with g.as_default():\n",
    "    with tf.Session(graph=g) as sess:\n",
    "#         img = tf.random_uniform(\n",
    "#                 (4, crop_size[0], crop_size[1], 1))\n",
    "        img = tf.convert_to_tensor(xx[...,np.newaxis], dtype=tf.uint8)\n",
    "        print(img.shape)\n",
    "        print(img.dtype)\n",
    "#         outputs_to_scales_to_logits = model.multi_scale_logits(\n",
    "#                                         inputs,\n",
    "#                                         model_options,\n",
    "#                                         image_pyramid=[1.0])\n",
    "\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "#         logits = sess.run(logits)\n",
    "#         outputs_to_scales_to_logits = sess.run(outputs_to_logits, feed_dict={'input_layer:0': img.eval(), 'training:0':True})\n",
    "        outputs = sess.run(logits, feed_dict={'input_layer:0': img.eval(), 'training:0':False})\n",
    "#         loss = sess.run(loss)\n",
    "#         output0 = sess.run(outputs_to_scales_to_logits)\n",
    "#         print(output0)\n",
    "        writer = tf.summary.FileWriter(\"output3/test3\", sess.graph)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
